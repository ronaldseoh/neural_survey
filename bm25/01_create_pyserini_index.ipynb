{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBxpNMJGVLf5"
   },
   "source": [
    "# Build `pyserini` Index for SemEval 2014 Task 4\n",
    "\n",
    "- We first convert the original `xml` dataset files into the document collection of `jsonl` format that `pyserini` understands.\n",
    "\n",
    "- We build a `Pyserini` index that includes all documents from train and test sets for both `laptop` and `restaurant`.\n",
    "\n",
    "- Lastly, generate `test_queries_{laptop, restaurant}.txt` and `test_qrels_{laptop, restaurant}.txt` out of the original test dataset, by treating each unique `(aspect, sentiment)` label as a query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab setups\n",
    "\n",
    "This part only gets executed if this notebook is being run under Google Colab. **Please change the working path  directory below in advance!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13577,
     "status": "ok",
     "timestamp": 1606720151425,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "Snoo7KkXVEg1",
    "outputId": "c17df6c7-5431-407f-cd3b-b43ffe17104b"
   },
   "outputs": [],
   "source": [
    "# Use Google Colab\n",
    "use_colab = True\n",
    "\n",
    "# Is this notebook running on Colab?\n",
    "# If so, then google.colab package (github.com/googlecolab/colabtools)\n",
    "# should be available in this environment\n",
    "\n",
    "# Previous version used importlib, but we could do the same thing with\n",
    "# just attempting to import google.colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    colab_available = True\n",
    "except:\n",
    "    colab_available = False\n",
    "\n",
    "if use_colab and colab_available:\n",
    "    # If there are packages I need to install separately, do it here\n",
    "    !pip install pyserini==0.9.4.0 jsonlines==1.2.0\n",
    "\n",
    "    # Mount Google Drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # cd to the appropriate working directory under my Google Drive\n",
    "    # (IMPORTANT: THIS PATH MUST MATCH EXACTLY TO WHERE THIS NOTEBOOK IS LOCATED\n",
    "    # IN YOUR GOOGLE DRIVE!!)\n",
    "    %cd '/content/drive/My Drive/CS646_Final_Project/BM25'\n",
    "\n",
    "    # List the directory contents\n",
    "    !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2926,
     "status": "ok",
     "timestamp": 1606720193794,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "L_bzlsQoVP9h"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json \n",
    "import random\n",
    "import xml.etree.ElementTree as ET\n",
    "import pathlib\n",
    "import math\n",
    "\n",
    "import jsonlines \n",
    "from pyserini.search import SimpleSearcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1182,
     "status": "ok",
     "timestamp": 1606720198370,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "Y8rYGQHPVmt4"
   },
   "outputs": [],
   "source": [
    "semeval_path = os.path.join('..', 'data', 'SemEval2014_Task4')\n",
    "collection_path = 'collection'\n",
    "index_path = 'index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is used to assign unique document ids across the different collections.\n",
    "collection_ids = {\n",
    "    'Laptop_Train_v2.xml': 1,\n",
    "    'Laptops_Test_Gold.xml': 2,\n",
    "    'Restaurants_Test_Gold.xml': 3,\n",
    "    'Restaurants_Train_v2.xml': 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MVMGUX1wWPmm"
   },
   "outputs": [],
   "source": [
    "# For fair comparision, generate collections for the original SemEval test datasets only\n",
    "new_collection_files = {\n",
    "   'Laptops_Test_Gold.xml': 'laptop_test/laptop_test.jsonl',\n",
    "   'Restaurants_Test_Gold.xml': 'restaurant_test/restaurant_test.jsonl',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_query_files = {\n",
    "   'Laptops_Test_Gold.xml': 'test_queries_laptop.txt',\n",
    "   'Restaurants_Test_Gold.xml': 'test_queries_restaurant.txt',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_qrels_files = {\n",
    "   'Laptops_Test_Gold.xml': {\n",
    "       'qrels_filename': 'test_qrels_laptop.txt',\n",
    "       'original_dataset_files': ['Laptops_Test_Gold.xml']\n",
    "   },\n",
    "   'Restaurants_Test_Gold.xml': {\n",
    "       'qrels_filename': 'test_qrels_restaurant.txt',\n",
    "       'original_dataset_files': ['Restaurants_Test_Gold.xml'] \n",
    "   },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2qDCigWWIhx"
   },
   "source": [
    "## Create collection (`jsonl` files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "executionInfo": {
     "elapsed": 1937,
     "status": "error",
     "timestamp": 1606715167209,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "Aw1wZ8voV3zQ",
    "outputId": "086a4d27-014f-4124-a96c-a7239c03e8cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collection/laptop_test/laptop_test.jsonl\n",
      "collection/restaurant_test/restaurant_test.jsonl\n"
     ]
    }
   ],
   "source": [
    "for file_name in new_collection_files.keys():\n",
    "    \n",
    "    file_path = os.path.join(semeval_path, file_name)\n",
    "\n",
    "    save_path = os.path.join(collection_path, new_collection_files[file_name])\n",
    "  \n",
    "    print(save_path)\n",
    "    \n",
    "    if os.path.exists(save_path):\n",
    "        !rm -r {save_path}\n",
    "    else:\n",
    "        pathlib.Path(save_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "        !touch {save_path}\n",
    "\n",
    "    with open(file_path) as semeval_file:\n",
    "        sentence_elements = ET.parse(semeval_file).getroot().iter('sentence')\n",
    "\n",
    "        for sentence_id, s in enumerate(sentence_elements):\n",
    "            sent = s.find('text').text\n",
    "\n",
    "            doc = {\n",
    "                'id': 'doc' + str(collection_ids[file_name]) + str(sentence_id),\n",
    "                'contents': sent,\n",
    "            }\n",
    "\n",
    "            with jsonlines.open(save_path, mode='a') as writer:\n",
    "                writer.write(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzMF15EhcztM"
   },
   "source": [
    "## Create `pyserini` index for laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5843,
     "status": "ok",
     "timestamp": 1606270899273,
     "user": {
      "displayName": "Zachary Harrison",
      "photoUrl": "",
      "userId": "15311225781645881460"
     },
     "user_tz": 420
    },
    "id": "WvvQoNhoczEQ",
    "outputId": "953834dd-daec-46b8-a894-5401227cae20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n",
      "2021-01-14 12:53:16,516 INFO  [main] index.IndexCollection (IndexCollection.java:636) - Setting log level to INFO\n",
      "2021-01-14 12:53:16,527 INFO  [main] index.IndexCollection (IndexCollection.java:639) - Starting indexer...\n",
      "2021-01-14 12:53:16,528 INFO  [main] index.IndexCollection (IndexCollection.java:640) - ============ Loading Parameters ============\n",
      "2021-01-14 12:53:16,530 INFO  [main] index.IndexCollection (IndexCollection.java:641) - DocumentCollection path: collection/laptop_test\n",
      "2021-01-14 12:53:16,532 INFO  [main] index.IndexCollection (IndexCollection.java:642) - CollectionClass: JsonCollection\n",
      "2021-01-14 12:53:16,534 INFO  [main] index.IndexCollection (IndexCollection.java:643) - Generator: DefaultLuceneDocumentGenerator\n",
      "2021-01-14 12:53:16,536 INFO  [main] index.IndexCollection (IndexCollection.java:644) - Threads: 1\n",
      "2021-01-14 12:53:16,538 INFO  [main] index.IndexCollection (IndexCollection.java:645) - Stemmer: porter\n",
      "2021-01-14 12:53:16,540 INFO  [main] index.IndexCollection (IndexCollection.java:646) - Keep stopwords? false\n",
      "2021-01-14 12:53:16,542 INFO  [main] index.IndexCollection (IndexCollection.java:647) - Stopwords:  null\n",
      "2021-01-14 12:53:16,543 INFO  [main] index.IndexCollection (IndexCollection.java:648) - Store positions? true\n",
      "2021-01-14 12:53:16,545 INFO  [main] index.IndexCollection (IndexCollection.java:649) - Store docvectors? true\n",
      "2021-01-14 12:53:16,555 INFO  [main] index.IndexCollection (IndexCollection.java:650) - Store document \"contents\" field? false\n",
      "2021-01-14 12:53:16,560 INFO  [main] index.IndexCollection (IndexCollection.java:651) - Store document \"raw\" field? true\n",
      "2021-01-14 12:53:16,563 INFO  [main] index.IndexCollection (IndexCollection.java:652) - Optimize (merge segments)? false\n",
      "2021-01-14 12:53:16,567 INFO  [main] index.IndexCollection (IndexCollection.java:653) - Whitelist: null\n",
      "2021-01-14 12:53:16,571 INFO  [main] index.IndexCollection (IndexCollection.java:673) - Directly building Lucene indexes...\n",
      "2021-01-14 12:53:16,574 INFO  [main] index.IndexCollection (IndexCollection.java:674) - Index path: index/laptop_test\n",
      "2021-01-14 12:53:16,637 INFO  [main] index.IndexCollection (IndexCollection.java:723) - ============ Indexing Collection ============\n",
      "2021-01-14 12:53:17,213 INFO  [main] index.IndexCollection (IndexCollection.java:784) - Thread pool with 1 threads initialized.\n",
      "2021-01-14 12:53:17,214 INFO  [main] index.IndexCollection (IndexCollection.java:786) - Initializing collection in collection/laptop_test\n",
      "2021-01-14 12:53:17,247 INFO  [main] index.IndexCollection (IndexCollection.java:789) - 1 file found\n",
      "2021-01-14 12:53:17,248 INFO  [main] index.IndexCollection (IndexCollection.java:790) - Starting to index...\n",
      "2021-01-14 12:53:19,553 DEBUG [pool-2-thread-1] index.IndexCollection$LocalIndexerThread (IndexCollection.java:238) - laptop_test/laptop_test.jsonl: 800 docs added.\n",
      "2021-01-14 12:53:22,011 INFO  [main] index.IndexCollection (IndexCollection.java:874) - Indexing Complete! 800 documents indexed\n",
      "2021-01-14 12:53:22,015 INFO  [main] index.IndexCollection (IndexCollection.java:875) - ============ Final Counter Values ============\n",
      "2021-01-14 12:53:22,016 INFO  [main] index.IndexCollection (IndexCollection.java:876) - indexed:              800\n",
      "2021-01-14 12:53:22,016 INFO  [main] index.IndexCollection (IndexCollection.java:877) - unindexable:            0\n",
      "2021-01-14 12:53:22,017 INFO  [main] index.IndexCollection (IndexCollection.java:878) - empty:                  0\n",
      "2021-01-14 12:53:22,018 INFO  [main] index.IndexCollection (IndexCollection.java:879) - skipped:                0\n",
      "2021-01-14 12:53:22,021 INFO  [main] index.IndexCollection (IndexCollection.java:880) - errors:                 0\n",
      "2021-01-14 12:53:22,049 INFO  [main] index.IndexCollection (IndexCollection.java:883) - Total 800 documents indexed in 00:00:05\n"
     ]
    }
   ],
   "source": [
    "!python -m pyserini.index -collection JsonCollection -generator DefaultLuceneDocumentGenerator \\\n",
    " -threads 1 -input collection/laptop_test \\\n",
    " -index index/laptop_test -storePositions -storeDocvectors -storeRaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `pyserini` index for restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n",
      "2021-01-14 12:56:42,371 INFO  [main] index.IndexCollection (IndexCollection.java:636) - Setting log level to INFO\n",
      "2021-01-14 12:56:42,381 INFO  [main] index.IndexCollection (IndexCollection.java:639) - Starting indexer...\n",
      "2021-01-14 12:56:42,382 INFO  [main] index.IndexCollection (IndexCollection.java:640) - ============ Loading Parameters ============\n",
      "2021-01-14 12:56:42,383 INFO  [main] index.IndexCollection (IndexCollection.java:641) - DocumentCollection path: collection/restaurant_test\n",
      "2021-01-14 12:56:42,384 INFO  [main] index.IndexCollection (IndexCollection.java:642) - CollectionClass: JsonCollection\n",
      "2021-01-14 12:56:42,385 INFO  [main] index.IndexCollection (IndexCollection.java:643) - Generator: DefaultLuceneDocumentGenerator\n",
      "2021-01-14 12:56:42,386 INFO  [main] index.IndexCollection (IndexCollection.java:644) - Threads: 1\n",
      "2021-01-14 12:56:42,389 INFO  [main] index.IndexCollection (IndexCollection.java:645) - Stemmer: porter\n",
      "2021-01-14 12:56:42,390 INFO  [main] index.IndexCollection (IndexCollection.java:646) - Keep stopwords? false\n",
      "2021-01-14 12:56:42,391 INFO  [main] index.IndexCollection (IndexCollection.java:647) - Stopwords:  null\n",
      "2021-01-14 12:56:42,394 INFO  [main] index.IndexCollection (IndexCollection.java:648) - Store positions? true\n",
      "2021-01-14 12:56:42,395 INFO  [main] index.IndexCollection (IndexCollection.java:649) - Store docvectors? true\n",
      "2021-01-14 12:56:42,397 INFO  [main] index.IndexCollection (IndexCollection.java:650) - Store document \"contents\" field? false\n",
      "2021-01-14 12:56:42,397 INFO  [main] index.IndexCollection (IndexCollection.java:651) - Store document \"raw\" field? true\n",
      "2021-01-14 12:56:42,399 INFO  [main] index.IndexCollection (IndexCollection.java:652) - Optimize (merge segments)? false\n",
      "2021-01-14 12:56:42,401 INFO  [main] index.IndexCollection (IndexCollection.java:653) - Whitelist: null\n",
      "2021-01-14 12:56:42,401 INFO  [main] index.IndexCollection (IndexCollection.java:673) - Directly building Lucene indexes...\n",
      "2021-01-14 12:56:42,402 INFO  [main] index.IndexCollection (IndexCollection.java:674) - Index path: index/restaurant_test\n",
      "2021-01-14 12:56:42,414 INFO  [main] index.IndexCollection (IndexCollection.java:723) - ============ Indexing Collection ============\n",
      "2021-01-14 12:56:43,146 INFO  [main] index.IndexCollection (IndexCollection.java:784) - Thread pool with 1 threads initialized.\n",
      "2021-01-14 12:56:43,147 INFO  [main] index.IndexCollection (IndexCollection.java:786) - Initializing collection in collection/restaurant_test\n",
      "2021-01-14 12:56:43,162 INFO  [main] index.IndexCollection (IndexCollection.java:789) - 1 file found\n",
      "2021-01-14 12:56:43,163 INFO  [main] index.IndexCollection (IndexCollection.java:790) - Starting to index...\n",
      "2021-01-14 12:56:46,143 DEBUG [pool-2-thread-1] index.IndexCollection$LocalIndexerThread (IndexCollection.java:238) - restaurant_test/restaurant_test.jsonl: 800 docs added.\n",
      "2021-01-14 12:56:48,402 INFO  [main] index.IndexCollection (IndexCollection.java:874) - Indexing Complete! 800 documents indexed\n",
      "2021-01-14 12:56:48,403 INFO  [main] index.IndexCollection (IndexCollection.java:875) - ============ Final Counter Values ============\n",
      "2021-01-14 12:56:48,403 INFO  [main] index.IndexCollection (IndexCollection.java:876) - indexed:              800\n",
      "2021-01-14 12:56:48,405 INFO  [main] index.IndexCollection (IndexCollection.java:877) - unindexable:            0\n",
      "2021-01-14 12:56:48,406 INFO  [main] index.IndexCollection (IndexCollection.java:878) - empty:                  0\n",
      "2021-01-14 12:56:48,407 INFO  [main] index.IndexCollection (IndexCollection.java:879) - skipped:                0\n",
      "2021-01-14 12:56:48,407 INFO  [main] index.IndexCollection (IndexCollection.java:880) - errors:                 0\n",
      "2021-01-14 12:56:48,443 INFO  [main] index.IndexCollection (IndexCollection.java:883) - Total 800 documents indexed in 00:00:05\n"
     ]
    }
   ],
   "source": [
    "!python -m pyserini.index -collection JsonCollection -generator DefaultLuceneDocumentGenerator \\\n",
    " -threads 1 -input collection/restaurant_test \\\n",
    " -index index/restaurant_test -storePositions -storeDocvectors -storeRaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2Z77zqnd7cG"
   },
   "source": [
    "## Test the new indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6980,
     "status": "ok",
     "timestamp": 1606720212568,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "8fnONT49d6W1",
    "outputId": "72f93bd5-63a1-4b6d-efd4-35f8b50a0d93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 doc20           4.30850\n",
      " 2 doc2523         3.11450\n",
      " 3 doc2568         2.65380\n",
      " 4 doc2273         2.54620\n",
      " 5 doc2346         1.90690\n",
      " 6 doc2672         1.90690\n",
      " 7 doc2130         1.86390\n",
      " 8 doc2721         1.86390\n",
      " 9 doc2358         1.82280\n",
      "10 doc2540         1.78340\n"
     ]
    }
   ],
   "source": [
    "from pyserini.search import SimpleSearcher\n",
    "\n",
    "idx_path = os.path.join('index', 'laptop_test')\n",
    "\n",
    "searcher = SimpleSearcher(idx_path)\n",
    "hits = searcher.search('Boot time')\n",
    "\n",
    "for i in range(len(hits)):\n",
    "    print(f'{i+1:2} {hits[i].docid:15} {hits[i].score:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 doc3560         2.62770\n",
      " 2 doc3457         2.57050\n",
      " 3 doc3625         2.57050\n",
      " 4 doc3506         2.46310\n",
      " 5 doc3330         2.31800\n",
      " 6 doc3556         1.81790\n",
      " 7 doc3710         1.73760\n"
     ]
    }
   ],
   "source": [
    "from pyserini.search import SimpleSearcher\n",
    "\n",
    "idx_path = os.path.join('index', 'restaurant_test')\n",
    "\n",
    "searcher = SimpleSearcher(idx_path)\n",
    "hits = searcher.search('quality')\n",
    "\n",
    "for i in range(len(hits)):\n",
    "    print(f'{i+1:2} {hits[i].docid:15} {hits[i].score:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdExwBsPNgVL"
   },
   "source": [
    "## Create test queries from the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_queries_laptop.txt\n",
      "Total number of queries: 654\n",
      "Total number of unique queries: 419\n",
      "\n",
      "test_queries_restaurant.txt\n",
      "Total number of queries: 1134\n",
      "Total number of unique queries: 555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for f in new_query_files.keys():\n",
    "    \n",
    "    file_path = os.path.join(semeval_path, f)\n",
    "  \n",
    "    save_path = new_query_files[f]\n",
    "  \n",
    "    print(save_path)\n",
    "    \n",
    "    queries = []\n",
    "\n",
    "    with open(file_path) as semeval_file:\n",
    "        sentence_elements = ET.parse(semeval_file).getroot().iter('sentence')\n",
    "\n",
    "        for id_, s in enumerate(sentence_elements):\n",
    "            sent = s.find('text').text\n",
    "            \n",
    "            for o in s.iter('aspectTerm'):\n",
    "                aspect_term = o.get('term')\n",
    "                \n",
    "                queries.append(aspect_term)\n",
    "                    \n",
    "    print(\"Total number of queries:\", len(queries))\n",
    "\n",
    "    unique_queries = list(set(queries))    \n",
    "    unique_queries.sort()\n",
    "\n",
    "    print(\"Total number of unique queries:\", len(unique_queries))\n",
    "    \n",
    "    print()\n",
    "\n",
    "    with open(save_path, 'w') as new_file:\n",
    "        for q in unique_queries:\n",
    "            new_file.write(\"%s\\n\" % q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RxPAszvnRE1F"
   },
   "source": [
    "## Create qrels.txt (ground truth) for test queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_qrels_laptop.txt\n",
      "Average # of relevant documents per query: 1.5536992840095465\n",
      "Min # of relevant documents: 1\n",
      "The query ID with min #: 0\n",
      "Max # of relevant documents: 17\n",
      "The query ID with max #: 313\n",
      "\n",
      "test_qrels_restaurant.txt\n",
      "Average # of relevant documents per query: 2.036036036036036\n",
      "Min # of relevant documents: 1\n",
      "The query ID with min #: 0\n",
      "Max # of relevant documents: 117\n",
      "The query ID with max #: 262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for f in new_qrels_files.keys():\n",
    "    \n",
    "    query_path = new_query_files[f]\n",
    "  \n",
    "    save_path = new_qrels_files[f]['qrels_filename']\n",
    "  \n",
    "    print(save_path)\n",
    "    \n",
    "    with open(query_path, 'r') as test_query_file:\n",
    "        unique_queries = test_query_file.readlines()\n",
    "\n",
    "    rel_docIDs = {}\n",
    "    \n",
    "    for j in range(len(unique_queries)):\n",
    "        rel_docIDs[j] = []\n",
    "        \n",
    "    for semeval_file_name in new_qrels_files[f]['original_dataset_files']:\n",
    "        \n",
    "        semeval_file_path = os.path.join(semeval_path, semeval_file_name)\n",
    "\n",
    "        with open(semeval_file_path) as semeval_file:\n",
    "            sentence_elements = ET.parse(semeval_file).getroot().iter('sentence')\n",
    "\n",
    "            for id_, s in enumerate(sentence_elements):\n",
    "                # doc_id used in our Pyserini index\n",
    "                doc_id = 'doc' + str(collection_ids[semeval_file_name]) + str(id_)\n",
    "            \n",
    "                for o in s.iter('aspectTerm'):\n",
    "                    aspect_term = o.get('term')\n",
    "\n",
    "                    for i, query in enumerate(unique_queries):\n",
    "                        if query.rstrip('\\n') == aspect_term:\n",
    "                            rel_docIDs[i].append(doc_id)\n",
    "\n",
    "    # write query/relevant doc pairs to qrels file\n",
    "    with open(save_path, 'w') as f:\n",
    "        for i in rel_docIDs.keys():\n",
    "            # Some documents may have two identical (aspect, term) labels\n",
    "            # because the aspect term occur multiple times within the sentence\n",
    "            rel_docIDs[i] = list(set(rel_docIDs[i]))\n",
    "            rel_docIDs[i].sort()\n",
    "\n",
    "            for rd in rel_docIDs[i]:\n",
    "                line = str(i+1) + '\\t' + '0' + '\\t' + rd + '\\t' + '1'\n",
    "                f.write(\"%s\\n\" % line)\n",
    "                \n",
    "    # Get the stats for the # of relevant documents per query\n",
    "    total_rel_documents = 0\n",
    "    min_rel_documents = math.inf\n",
    "    min_rel_query_id = -1\n",
    "    max_rel_documents = -math.inf\n",
    "    max_rel_query_id = -1\n",
    "    \n",
    "    for i in rel_docIDs.keys():\n",
    "        total_rel_documents = total_rel_documents + len(rel_docIDs[i])\n",
    "        \n",
    "        if len(rel_docIDs[i]) < min_rel_documents:\n",
    "            min_rel_documents = len(rel_docIDs[i])\n",
    "            min_rel_query_id = i\n",
    "            \n",
    "        if len(rel_docIDs[i]) > max_rel_documents:\n",
    "            max_rel_documents = len(rel_docIDs[i])\n",
    "            max_rel_query_id = i\n",
    "        \n",
    "    print(\"Average # of relevant documents per query:\", total_rel_documents/len(unique_queries))\n",
    "    \n",
    "    print(\"Min # of relevant documents:\", min_rel_documents)\n",
    "    print(\"The query ID with min #:\", min_rel_query_id)\n",
    "\n",
    "    print(\"Max # of relevant documents:\", max_rel_documents)\n",
    "    print(\"The query ID with max #:\", max_rel_query_id)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "create_pyserini_index.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBxpNMJGVLf5"
   },
   "source": [
    "# Build `pyserini` Index for SemEval 2014 Task 4\n",
    "\n",
    "- We first convert the original `xml` dataset files into the document collection of `jsonl` format that `pyserini` understands.\n",
    "\n",
    "- We build a `Pyserini` index that includes all documents from train and test sets for both `laptop` and `restaurant`.\n",
    "\n",
    "- Lastly, generate `test_queries_{laptop, restaurant}.txt` and `test_qrels_{laptop, restaurant}.txt` out of the original test dataset, by treating each unique `(aspect, sentiment)` label as a query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab setups\n",
    "\n",
    "This part only gets executed if this notebook is being run under Google Colab. **Please change the working path  directory below in advance!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13577,
     "status": "ok",
     "timestamp": 1606720151425,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "Snoo7KkXVEg1",
    "outputId": "c17df6c7-5431-407f-cd3b-b43ffe17104b"
   },
   "outputs": [],
   "source": [
    "# Use Google Colab\n",
    "use_colab = True\n",
    "\n",
    "# Is this notebook running on Colab?\n",
    "# If so, then google.colab package (github.com/googlecolab/colabtools)\n",
    "# should be available in this environment\n",
    "\n",
    "# Previous version used importlib, but we could do the same thing with\n",
    "# just attempting to import google.colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    colab_available = True\n",
    "except:\n",
    "    colab_available = False\n",
    "\n",
    "if use_colab and colab_available:\n",
    "    # If there are packages I need to install separately, do it here\n",
    "    !pip install pyserini==0.9.4.0 jsonlines==1.2.0\n",
    "\n",
    "    # Mount Google Drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # cd to the appropriate working directory under my Google Drive\n",
    "    # (IMPORTANT: THIS PATH MUST MATCH EXACTLY TO WHERE THIS NOTEBOOK IS LOCATED\n",
    "    # IN YOUR GOOGLE DRIVE!!)\n",
    "    %cd '/content/drive/My Drive/CS646_Final_Project/BM25'\n",
    "\n",
    "    # List the directory contents\n",
    "    !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2926,
     "status": "ok",
     "timestamp": 1606720193794,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "L_bzlsQoVP9h"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json \n",
    "import random\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from tqdm import tqdm\n",
    "import jsonlines \n",
    "from pyserini.search import SimpleSearcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1182,
     "status": "ok",
     "timestamp": 1606720198370,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "Y8rYGQHPVmt4"
   },
   "outputs": [],
   "source": [
    "semeval_path = os.path.join('..', 'data', 'SemEval2014_Task4')\n",
    "collection_path = 'collection'\n",
    "index_path = 'index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MVMGUX1wWPmm"
   },
   "outputs": [],
   "source": [
    "new_collection_files = {\n",
    "   'Laptop_Train_v2.xml': 'laptop_train.jsonl',\n",
    "   'Laptops_Test_Gold.xml': 'laptop_test.jsonl',\n",
    "   'Restaurants_Test_Gold.xml': 'restaurant_test.jsonl',\n",
    "   'Restaurants_Train_v2.xml': 'restaurant_train.jsonl'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_query_files = {\n",
    "   'Laptops_Test_Gold.xml': 'test_queries_laptop.txt',\n",
    "   'Restaurants_Test_Gold.xml': 'test_queries_restaurant.txt',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_qrels_files = {\n",
    "   'Laptops_Test_Gold.xml': 'test_qrels_laptop.txt',\n",
    "   'Restaurants_Test_Gold.xml': 'test_qrels_restaurant.txt',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2qDCigWWIhx"
   },
   "source": [
    "## Create collection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "executionInfo": {
     "elapsed": 1937,
     "status": "error",
     "timestamp": 1606715167209,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "Aw1wZ8voV3zQ",
    "outputId": "086a4d27-014f-4124-a96c-a7239c03e8cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/SemEval2014_Task4/Laptop_Train_v2.xml\n",
      "../data/SemEval2014_Task4/Laptops_Test_Gold.xml\n",
      "../data/SemEval2014_Task4/Restaurants_Test_Gold.xml\n",
      "../data/SemEval2014_Task4/Restaurants_Train_v2.xml\n"
     ]
    }
   ],
   "source": [
    "for file_id, f in enumerate(new_collection_files.keys()):\n",
    "    \n",
    "    file_path = os.path.join(semeval_path, f)\n",
    "  \n",
    "    save_path = os.path.join(collection_path, new_collection_files[f])\n",
    "  \n",
    "    print(save_path)\n",
    "\n",
    "    with open(file_path) as semeval_file:\n",
    "        sentence_elements = ET.parse(semeval_file).getroot().iter('sentence')\n",
    "\n",
    "        for id_, s in enumerate(sentence_elements):\n",
    "            sent = s.find('text').text\n",
    "\n",
    "            doc = {\n",
    "                'id': 'doc' + str(file_id) + str(id_),\n",
    "                'contents': sent,\n",
    "            }\n",
    "\n",
    "            with jsonlines.open(save_path, mode='a') as writer:\n",
    "                writer.write(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzMF15EhcztM"
   },
   "source": [
    "## Create `pyserini` index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5843,
     "status": "ok",
     "timestamp": 1606270899273,
     "user": {
      "displayName": "Zachary Harrison",
      "photoUrl": "",
      "userId": "15311225781645881460"
     },
     "user_tz": 420
    },
    "id": "WvvQoNhoczEQ",
    "outputId": "953834dd-daec-46b8-a894-5401227cae20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n",
      "2020-12-06 14:17:02,379 INFO  [main] index.IndexCollection (IndexCollection.java:636) - Setting log level to INFO\n",
      "2020-12-06 14:17:02,407 INFO  [main] index.IndexCollection (IndexCollection.java:639) - Starting indexer...\n",
      "2020-12-06 14:17:02,408 INFO  [main] index.IndexCollection (IndexCollection.java:640) - ============ Loading Parameters ============\n",
      "2020-12-06 14:17:02,410 INFO  [main] index.IndexCollection (IndexCollection.java:641) - DocumentCollection path: collection\n",
      "2020-12-06 14:17:02,413 INFO  [main] index.IndexCollection (IndexCollection.java:642) - CollectionClass: JsonCollection\n",
      "2020-12-06 14:17:02,415 INFO  [main] index.IndexCollection (IndexCollection.java:643) - Generator: DefaultLuceneDocumentGenerator\n",
      "2020-12-06 14:17:02,417 INFO  [main] index.IndexCollection (IndexCollection.java:644) - Threads: 1\n",
      "2020-12-06 14:17:02,420 INFO  [main] index.IndexCollection (IndexCollection.java:645) - Stemmer: porter\n",
      "2020-12-06 14:17:02,421 INFO  [main] index.IndexCollection (IndexCollection.java:646) - Keep stopwords? false\n",
      "2020-12-06 14:17:02,422 INFO  [main] index.IndexCollection (IndexCollection.java:647) - Stopwords:  null\n",
      "2020-12-06 14:17:02,423 INFO  [main] index.IndexCollection (IndexCollection.java:648) - Store positions? true\n",
      "2020-12-06 14:17:02,428 INFO  [main] index.IndexCollection (IndexCollection.java:649) - Store docvectors? true\n",
      "2020-12-06 14:17:02,434 INFO  [main] index.IndexCollection (IndexCollection.java:650) - Store document \"contents\" field? false\n",
      "2020-12-06 14:17:02,436 INFO  [main] index.IndexCollection (IndexCollection.java:651) - Store document \"raw\" field? true\n",
      "2020-12-06 14:17:02,437 INFO  [main] index.IndexCollection (IndexCollection.java:652) - Optimize (merge segments)? false\n",
      "2020-12-06 14:17:02,441 INFO  [main] index.IndexCollection (IndexCollection.java:653) - Whitelist: null\n",
      "2020-12-06 14:17:02,446 INFO  [main] index.IndexCollection (IndexCollection.java:673) - Directly building Lucene indexes...\n",
      "2020-12-06 14:17:02,450 INFO  [main] index.IndexCollection (IndexCollection.java:674) - Index path: index\n",
      "2020-12-06 14:17:02,471 INFO  [main] index.IndexCollection (IndexCollection.java:723) - ============ Indexing Collection ============\n",
      "2020-12-06 14:17:03,090 INFO  [main] index.IndexCollection (IndexCollection.java:784) - Thread pool with 1 threads initialized.\n",
      "2020-12-06 14:17:03,092 INFO  [main] index.IndexCollection (IndexCollection.java:786) - Initializing collection in collection\n",
      "2020-12-06 14:17:03,138 INFO  [main] index.IndexCollection (IndexCollection.java:789) - 4 files found\n",
      "2020-12-06 14:17:03,146 INFO  [main] index.IndexCollection (IndexCollection.java:790) - Starting to index...\n",
      "2020-12-06 14:17:07,589 DEBUG [pool-2-thread-1] index.IndexCollection$LocalIndexerThread (IndexCollection.java:238) - collection/laptop_train.jsonl: 3045 docs added.\n",
      "2020-12-06 14:17:07,940 DEBUG [pool-2-thread-1] index.IndexCollection$LocalIndexerThread (IndexCollection.java:238) - collection/laptop_test.jsonl: 800 docs added.\n",
      "2020-12-06 14:17:08,267 DEBUG [pool-2-thread-1] index.IndexCollection$LocalIndexerThread (IndexCollection.java:238) - collection/restaurant_test.jsonl: 800 docs added.\n",
      "2020-12-06 14:17:09,239 DEBUG [pool-2-thread-1] index.IndexCollection$LocalIndexerThread (IndexCollection.java:238) - collection/restaurant_train.jsonl: 3041 docs added.\n",
      "2020-12-06 14:17:11,168 INFO  [main] index.IndexCollection (IndexCollection.java:874) - Indexing Complete! 7,686 documents indexed\n",
      "2020-12-06 14:17:11,169 INFO  [main] index.IndexCollection (IndexCollection.java:875) - ============ Final Counter Values ============\n",
      "2020-12-06 14:17:11,169 INFO  [main] index.IndexCollection (IndexCollection.java:876) - indexed:            7,686\n",
      "2020-12-06 14:17:11,173 INFO  [main] index.IndexCollection (IndexCollection.java:877) - unindexable:            0\n",
      "2020-12-06 14:17:11,174 INFO  [main] index.IndexCollection (IndexCollection.java:878) - empty:                  0\n",
      "2020-12-06 14:17:11,174 INFO  [main] index.IndexCollection (IndexCollection.java:879) - skipped:                0\n",
      "2020-12-06 14:17:11,181 INFO  [main] index.IndexCollection (IndexCollection.java:880) - errors:                 0\n",
      "2020-12-06 14:17:11,247 INFO  [main] index.IndexCollection (IndexCollection.java:883) - Total 7,686 documents indexed in 00:00:08\n"
     ]
    }
   ],
   "source": [
    "!python -m pyserini.index -collection JsonCollection -generator DefaultLuceneDocumentGenerator \\\n",
    " -threads 1 -input collection \\\n",
    " -index index -storePositions -storeDocvectors -storeRaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2Z77zqnd7cG"
   },
   "source": [
    "## Test the new index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6980,
     "status": "ok",
     "timestamp": 1606720212568,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "8fnONT49d6W1",
    "outputId": "72f93bd5-63a1-4b6d-efd4-35f8b50a0d93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 doc10           4.41670\n",
      " 2 doc31766        4.16470\n",
      " 3 doc0562         3.75720\n",
      " 4 doc31130        3.62740\n",
      " 5 doc1625         3.48300\n",
      " 6 doc1523         3.38260\n",
      " 7 doc31974        3.38260\n",
      " 8 doc2255         3.34980\n",
      " 9 doc02921        3.30620\n",
      "10 doc3393         3.28690\n"
     ]
    }
   ],
   "source": [
    "from pyserini.search import SimpleSearcher\n",
    "\n",
    "idx_path = os.path.join('index')\n",
    "\n",
    "searcher = SimpleSearcher(idx_path)\n",
    "hits = searcher.search('Boot time, positive')\n",
    "\n",
    "for i in range(len(hits)):\n",
    "    print(f'{i+1:2} {hits[i].docid:15} {hits[i].score:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdExwBsPNgVL"
   },
   "source": [
    "## Create test queries from the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_queries_laptop.txt\n",
      "Total number of queries: 638\n",
      "Total number of unique queries: 475\n",
      "\n",
      "test_queries_restaurant.txt\n",
      "Total number of queries: 1120\n",
      "Total number of unique queries: 642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file_id, f in enumerate(new_query_files.keys()):\n",
    "    \n",
    "    file_path = os.path.join(semeval_path, f)\n",
    "  \n",
    "    save_path = new_query_files[f]\n",
    "  \n",
    "    print(save_path)\n",
    "    \n",
    "    queries = []\n",
    "\n",
    "    with open(file_path) as semeval_file:\n",
    "        sentence_elements = ET.parse(semeval_file).getroot().iter('sentence')\n",
    "\n",
    "        for id_, s in enumerate(sentence_elements):\n",
    "            sent = s.find('text').text\n",
    "            \n",
    "            for o in s.iter('aspectTerm'):\n",
    "                aspect_term = o.get('term')\n",
    "                sentiment = o.get('polarity')\n",
    "                \n",
    "                # Ignore \"conflict\" labels\n",
    "                if sentiment != 'conflict':\n",
    "                    queries.append(aspect_term + ', ' + sentiment)\n",
    "                    \n",
    "    print(\"Total number of queries:\", len(queries))\n",
    "\n",
    "    # WARNING: This makes the queries to be stored in a random order.\n",
    "    unique_queries = set(queries)\n",
    "\n",
    "    print(\"Total number of unique queries:\", len(unique_queries))\n",
    "    \n",
    "    print()\n",
    "\n",
    "    with open(save_path, 'w') as new_file:\n",
    "        for q in unique_queries:\n",
    "            new_file.write(\"%s\\n\" % q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RxPAszvnRE1F"
   },
   "source": [
    "## Create qrels.txt (ground truth) for test queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_qrels_laptop.txt\n",
      "test_qrels_restaurant.txt\n"
     ]
    }
   ],
   "source": [
    "for file_id, f in enumerate(new_qrels_files.keys()):\n",
    "    \n",
    "    file_path = os.path.join(semeval_path, f)\n",
    "    \n",
    "    query_path = new_query_files[f]\n",
    "  \n",
    "    save_path = new_qrels_files[f]\n",
    "  \n",
    "    print(save_path)\n",
    "    \n",
    "    with open(query_path, 'r') as test_query_file:\n",
    "        unique_queries = test_query_file.readlines()\n",
    "\n",
    "    rel_docIDs = {}\n",
    "    \n",
    "    for j in range(len(unique_queries)):\n",
    "        rel_docIDs[j] = []\n",
    "\n",
    "    with open(file_path) as semeval_file:\n",
    "        sentence_elements = ET.parse(semeval_file).getroot().iter('sentence')\n",
    "\n",
    "        for id_, s in enumerate(sentence_elements):\n",
    "            # doc_id used in our Pyserini index\n",
    "            doc_id = 'doc' + str(file_id) + str(id_)\n",
    "            \n",
    "            for o in s.iter('aspectTerm'):\n",
    "                aspect_term = o.get('term')\n",
    "                sentiment = o.get('polarity')\n",
    "\n",
    "                # Ignore \"conflict\" labels\n",
    "                if sentiment != 'conflict':\n",
    "                    for i, query in enumerate(unique_queries):\n",
    "                        query_split = query.split(',')\n",
    "\n",
    "                        if query_split[0] == aspect_term and query_split[1].strip() == sentiment:\n",
    "                            rel_docIDs[i].append(doc_id)\n",
    "\n",
    "    # write query/relevant doc pairs to qrels file\n",
    "    with open(save_path, 'w') as f:\n",
    "        for i in rel_docIDs.keys():\n",
    "            for rd in rel_docIDs[i]:\n",
    "                line = str(i+1) + '\\t' + '0' + '\\t' + rd + '\\t' + '1'\n",
    "                f.write(\"%s\\n\" % line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29343,
     "status": "ok",
     "timestamp": 1606230077443,
     "user": {
      "displayName": "Zachary Harrison",
      "photoUrl": "",
      "userId": "15311225781645881460"
     },
     "user_tz": 420
    },
    "id": "odt5w0nSRJu0",
    "outputId": "74c0d432-ddfb-4074-9329-b24410b1fec8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '../BM25/qrels_restaurant.txt': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# loop through all unique queries\n",
    "#   loop through all document json files and keep track of relevant ones\n",
    "#   write to qrels file [query #, 0, docID, 1]\n",
    "\n",
    "qrels_path = os.path.join('../', 'BM25', 'qrels_restaurant.txt')\n",
    "\n",
    "# remove if already exist because appending\n",
    "!rm ../BM25/qrels_restaurant.txt\n",
    "\n",
    "for i, query in enumerate(unique_queries):\n",
    "  rel_docIDs = []\n",
    "\n",
    "  for file in all_files:\n",
    "    filepath = os.path.join(collection_path, file)\n",
    "\n",
    "    with jsonlines.open(filepath) as reader:\n",
    "      for obj in reader:\n",
    "        docID = obj['id']\n",
    "\n",
    "        for asp in obj['aspects']:\n",
    "          q = asp[0] + ', ' + asp[1]\n",
    "\n",
    "          # if aspect sent pair matches query, add docID to relevant doc list\n",
    "          if query == q:\n",
    "            rel_docIDs.append(docID)\n",
    "  \n",
    "  rel_docIDs = set(rel_docIDs)\n",
    "\n",
    "  # write query/relevant doc pairs to qrels file\n",
    "  with open(qrels_path, 'a') as f:\n",
    "    for rd in rel_docIDs:\n",
    "      line = str(i+1) + '\\t' + '0' + '\\t' + rd + '\\t' + '1'\n",
    "      f.write(\"%s\\n\" % line)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "create_pyserini_index.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

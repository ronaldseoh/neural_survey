{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQ4YjJ32VSqE"
   },
   "source": [
    "# Create the training dataset for Siamese (Cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab setups\n",
    "\n",
    "This part only gets executed if this notebook is being run under Google Colab. **Please change the working path  directory below in advance!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25958,
     "status": "ok",
     "timestamp": 1606322127221,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "4RIIm8mCVhvL",
    "outputId": "1b31b29f-ed72-43c0-d5dc-6b97b1cb05b7"
   },
   "outputs": [],
   "source": [
    "# Use Google Colab\n",
    "use_colab = True\n",
    "\n",
    "# Is this notebook running on Colab?\n",
    "# If so, then google.colab package (github.com/googlecolab/colabtools)\n",
    "# should be available in this environment\n",
    "\n",
    "# Previous version used importlib, but we could do the same thing with\n",
    "# just attempting to import google.colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    colab_available = True\n",
    "except:\n",
    "    colab_available = False\n",
    "\n",
    "if use_colab and colab_available:\n",
    "    # If there are packages I need to install separately, do it here\n",
    "    #!pip install pyserini==0.9.4.0\n",
    "\n",
    "    # Mount Google Drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # cd to the appropriate working directory under my Google Drive\n",
    "    # (IMPORTANT: THIS PATH MUST MATCH EXACTLY TO WHERE THIS NOTEBOOK IS LOCATED\n",
    "    # IN YOUR GOOGLE DRIVE!!)\n",
    "    %cd '/content/drive/My Drive/CS646_Final_Project/data'\n",
    "\n",
    "    # List the directory contents\n",
    "    !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 25954,
     "status": "ok",
     "timestamp": 1606322127225,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "FCuQaHmCTrhX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import pathlib\n",
    "\n",
    "from tqdm import tqdm\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 25952,
     "status": "ok",
     "timestamp": 1606322127228,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "zQ_1IFd2zV2v"
   },
   "outputs": [],
   "source": [
    "# Random seed settings\n",
    "random_seed = 646\n",
    "random.seed(random_seed) # Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 25950,
     "status": "ok",
     "timestamp": 1606322127230,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "UU7n-IVPVbd4"
   },
   "outputs": [],
   "source": [
    "semeval_path = os.path.join('.', 'SemEval2014_Task4')\n",
    "our_path = os.path.join('.', 'our_datasets_partially_correct_labels_cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 25947,
     "status": "ok",
     "timestamp": 1606322127231,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "S9sD4wBABUO6"
   },
   "outputs": [],
   "source": [
    "pathlib.Path(our_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25940,
     "status": "ok",
     "timestamp": 1606322127232,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "SLiyd3HAXtmd",
    "outputId": "3b25a676-65aa-4e3d-d84e-d47875e6addd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PLACE_SEMEVAL_DATASET_FILES_HERE', 'Laptop_Train_v2.xml', 'Restaurants_Train_v2.xml', 'Laptops_Test_Gold.xml', 'Restaurants_Test_Gold.xml']\n"
     ]
    }
   ],
   "source": [
    "semeval_files = os.listdir(semeval_path)\n",
    "print(semeval_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 25936,
     "status": "ok",
     "timestamp": 1606322127234,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "NtYWBrYMoO_K"
   },
   "outputs": [],
   "source": [
    "new_files = {\n",
    "   'Laptop_Train_v2.xml': 'laptop_train.json',\n",
    "   'Restaurants_Train_v2.xml': 'restaurant_train.json',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtF4EtMqVXEv"
   },
   "source": [
    "## Process SemEval data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54928,
     "status": "ok",
     "timestamp": 1606322156236,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "UXh-cSRjVWmu",
    "outputId": "987e91c5-bff5-4f4f-ebe3-b42a18fabb95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Laptop_Train_v2.xml\n",
      "found 1250/2313 unique queries.\n",
      "found 3045 documents.\n",
      "generated 2848750 examples, 2279 positive 2107 aspect only, 992013 sentiment only, 1852351 negative.\n",
      "final generated 8940 examples, 2279 positive 2107 aspect only, 2275 sentiment only, 2279 negative.\n",
      "saving to: ./our_datasets_partially_correct_labels_cosine/laptop_train.json.\n",
      "\n",
      "Processing Restaurants_Train_v2.xml\n",
      "found 1560/3602 unique queries.\n",
      "found 3041 documents.\n",
      "generated 5584800 examples, 3580 positive 4205 aspect only, 2390610 sentiment only, 3186405 negative.\n",
      "final generated 14884 examples, 3580 positive 4205 aspect only, 3567 sentiment only, 3532 negative.\n",
      "saving to: ./our_datasets_partially_correct_labels_cosine/restaurant_train.json.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for f in new_files.keys():\n",
    "    print(\"Processing\", f)\n",
    "\n",
    "    file_path = os.path.join(semeval_path, f)\n",
    "    save_path = os.path.join(our_path, new_files[f])\n",
    "\n",
    "    # find unique queries\n",
    "    with open(file_path) as semeval_file:\n",
    "        sentence_elements = ET.parse(semeval_file).getroot().iter('sentence')\n",
    "\n",
    "        all_queries = []\n",
    "\n",
    "        for id_, s in enumerate(sentence_elements):\n",
    "            for o in s.iter('aspectTerm'):\n",
    "                aspect = o.get('term')\n",
    "                sentiment = o.get('polarity')\n",
    "\n",
    "                if sentiment != 'conflict': \n",
    "                    all_queries.append((aspect,sentiment))\n",
    "\n",
    "        queries = list(set(all_queries))\n",
    "        queries.sort()\n",
    "\n",
    "        print('found {}/{} unique queries.'.format(len(queries), len(all_queries)))\n",
    "\n",
    "    # find document, (aspect, sentiment) pairs (documents and their relevance judgements)\n",
    "    with open(file_path) as semeval_file:\n",
    "        sentence_elements = ET.parse(semeval_file).getroot().iter('sentence')\n",
    "\n",
    "        all_docs = []\n",
    "    \n",
    "        for doc_id, s in enumerate(sentence_elements): \n",
    "            doc = s.find('text').text\n",
    "\n",
    "            as_pairs = []\n",
    "\n",
    "            for o in s.iter('aspectTerm'):\n",
    "                aspect = o.get('term')\n",
    "                sentiment = o.get('polarity')\n",
    "\n",
    "                if sentiment == 'conflict':\n",
    "                    continue \n",
    "\n",
    "                as_pairs.append((aspect, sentiment))\n",
    "                \n",
    "            as_pairs = list(set(as_pairs))\n",
    "            as_pairs.sort()\n",
    "\n",
    "            all_docs.append({'doc': doc, 'pairs': as_pairs})\n",
    "\n",
    "        print('found {} documents.'.format(len(all_docs)))\n",
    "\n",
    "    examples = []\n",
    "\n",
    "    num_pos = 0\n",
    "    num_aspect_only = 0\n",
    "    num_sentiment_only = 0\n",
    "    num_neg = 0 \n",
    "\n",
    "    # create examples for all unique queries and docs \n",
    "    for query_id, query in enumerate(queries):\n",
    "        # print('current unique query: {}'.format(query))\n",
    "        for doc_id, doc_ex in enumerate(all_docs):\n",
    "            # print(cur_qs)\n",
    "\n",
    "            # If `query = (aspect, sentiment)` is in one of the [(aspect, sentiment)] labels\n",
    "            for aspect_sentiment in doc_ex['pairs']:\n",
    "                if query[0] == aspect_sentiment[0] and query[1] == aspect_sentiment[1]:\n",
    "                    label = 1 # This is a relevant document\n",
    "                    num_pos += 1\n",
    "                elif query[0] == aspect_sentiment[0]: # If only the aspect label matches\n",
    "                    label = 0.7\n",
    "                    num_aspect_only += 1\n",
    "                elif query[1] == aspect_sentiment[1]: # Sentiment label only\n",
    "                    label = 0.2\n",
    "                    num_sentiment_only += 1\n",
    "                else: # Both labels not matching\n",
    "                    label = 0\n",
    "                    num_neg += 1\n",
    "        \n",
    "                example = {\n",
    "                    'query_id': query_id,\n",
    "                    'query': query,\n",
    "                    'doc_id': doc_id,\n",
    "                    'doc': doc_ex['doc'],\n",
    "                    'label': label\n",
    "                }\n",
    "\n",
    "                examples.append(example)\n",
    "\n",
    "    print('generated {} examples, {} positive {} aspect only, {} sentiment only, {} negative.'.format(len(examples), num_pos, num_aspect_only, num_sentiment_only, num_neg))\n",
    "\n",
    "    # sample negative examples to get more even distribution\n",
    "    final_examples = []\n",
    "\n",
    "    new_num_aspect_only = 0\n",
    "    new_num_sentiment_only = 0\n",
    "    new_num_neg = 0\n",
    "\n",
    "    for example in examples:\n",
    "        if example['label'] == 1:\n",
    "            final_examples.append(example)\n",
    "        else:\n",
    "\n",
    "            if example['label'] == 0.7:\n",
    "                sample_rate = int(num_aspect_only/num_pos)\n",
    "\n",
    "                if sample_rate <= 1:\n",
    "                    final_examples.append(example)\n",
    "                    new_num_aspect_only += 1\n",
    "                else:\n",
    "                    if random.randint(0, sample_rate-1) != (sample_rate-1):\n",
    "                        continue\n",
    "\n",
    "                    final_examples.append(example)\n",
    "                    new_num_aspect_only += 1\n",
    "\n",
    "            elif example['label'] == 0.2:\n",
    "                sample_rate = int(num_sentiment_only/num_pos)\n",
    "\n",
    "                if sample_rate <= 1:\n",
    "                    final_examples.append(example)\n",
    "                    new_num_sentiment_only += 1\n",
    "                else:\n",
    "                    if random.randint(0, sample_rate-1) != (sample_rate-1):\n",
    "                        continue\n",
    "\n",
    "                    final_examples.append(example)\n",
    "                    new_num_sentiment_only += 1\n",
    "\n",
    "            else:\n",
    "                sample_rate = int(num_neg/num_pos)\n",
    "\n",
    "                if sample_rate <= 1:\n",
    "                    final_examples.append(example)\n",
    "                    new_num_neg += 1\n",
    "                else:\n",
    "                    if random.randint(0, sample_rate-1) != (sample_rate-1):\n",
    "                        continue\n",
    "\n",
    "                    final_examples.append(example)\n",
    "                    new_num_neg += 1\n",
    "\n",
    "    print('final generated {} examples, {} positive {} aspect only, {} sentiment only, {} negative.'.format(len(final_examples), num_pos, new_num_aspect_only, new_num_sentiment_only, new_num_neg))\n",
    "\n",
    "    # write file\n",
    "    print('saving to: {}.'.format(save_path))\n",
    "    \n",
    "    with open(save_path, 'w') as fout:\n",
    "        json.dump(final_examples , fout)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54923,
     "status": "ok",
     "timestamp": 1606322156238,
     "user": {
      "displayName": "Ronald Seoh",
      "photoUrl": "",
      "userId": "10284188050297676522"
     },
     "user_tz": 300
    },
    "id": "DXaVdryPqkMU",
    "outputId": "cdf1b53c-7c89-40ae-be89-f76bf841315d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_id': 0,\n",
       " 'query': (\"'gourmet' Indian cuisine\", 'neutral'),\n",
       " 'doc_id': 103,\n",
       " 'doc': 'The atmosphere is unheralded, the service impecible, and the food magnificant.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_examples[0]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "create_dataset_partially_correct_cosine.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
